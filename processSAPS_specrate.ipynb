{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting SAP Sales & Distribution Benchmark Results from cint_rate_base2006 Results\n",
    "In this notebook, we attempt to correlate SPEC cint_rate_base2006 with SAPS on the SAP Sales & Distribution 2-tier benchmark.\n",
    "\n",
    "https://www.sap.com/dmc/exp/2018-benchmark-directory/#/sd\n",
    "\n",
    "This is because there is a much larger volume of cint_rate_base2006 data, as compared to SAP SD2 data. If we accept the assumption that SAP SD2 is a reasonable approximation of an enterprise workload, and if we can find a good correlation between cint_rate_base2006 and SAP SD2, then we can size enterprise workloads directly using cint_rate_base2006 data, whch is quite abundant.\n",
    "\n",
    "In a previous notebook, I've consolidated cint_rate_base2006 and cint_rate_base2017 data and normalized to cint_rate_base2006 to provide a larger sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O export-sd.csv https://www.sap.com/dmc/exp/2018-benchmark-directory/assets/export-sd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsaps = pd.read_csv(\"export-sd.csv\", sep=\";\", error_bad_lines=False, header=0, encoding = \"ISO8859-1\")\n",
    "\n",
    "dfsaps['Server Name'] = dfsaps['Server Name'].str.upper() \n",
    "dfsaps['CPU Architecture'] = dfsaps['CPU Architecture'].str.upper() \n",
    "dfsaps['CPU Speed'] = dfsaps['CPU Speed'].str.upper() \n",
    "dfsaps['Technology Partner'] = dfsaps['Technology Partner'].str.upper() \n",
    "\n",
    "# we should only get 2-tier results\n",
    "dfsaps = dfsaps[ dfsaps['Configuration'] == '2-tier' ]\n",
    "\n",
    "dfsaps = dfsaps.drop(dfsaps.columns[[8, 12, 13, 14, 22, 24]], axis=1)\n",
    "\n",
    "# unfortunately some of the benchmarks have incorrect core counts\n",
    "# e.g. 2005021 has a null value for Cores in the CSV (but the long description shows 32 processors)\n",
    "# so we just drop any entries where Cores is not defined\n",
    "\n",
    "dfsaps.dropna(subset=['Cores'], inplace=True)\n",
    "dfsaps.to_csv(\"saps.csv\", index=False)\n",
    "\n",
    "dfsaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Derive Correlation Between SAPS and SPEC\n",
    "SAPS is a whole-system, complex benchmark, which is more relevant for enterprise workloads. However, the number of available SAPS benchmarks is low and mostly biased towards large, high end systems.\n",
    "\n",
    "If we can find a strong correlation between SAPS and SPEC, then we can use SPEC as a proxy for estimating performance of different processor architectures on SAPS-like, enterprise workloads.\n",
    "\n",
    "Rather than manually looking up cint_rate_base2006 values for every entry in the SAPS SD2 benchmark, we first attempt to automatically match them; because cint_rate_base2006 benchmarks don't break out the processor version, cores, and clock speed as separate fields in the summary, we have to do some parsing. To get a better match, we only use SAPS with \"INTEL XEON\" in the CPU Architecture description. This is 296 entries which is a little less than half of the total entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfintel = dfsaps[ (dfsaps['CPU Architecture'].str.contains(r'^INTEL XEON')) ]\n",
    "\n",
    "dfintel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SPEC ratings, and extract only those for INTEL XEON where a clock speed is specified in SYSTEM NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspec = pd.read_csv(\"specrate.csv\")\n",
    "\n",
    "# only get the SPEC results for INTEL XEON which have a clock speed (so we can match it to the SAPS dataframe)\n",
    "dfspecintel = dfspec[ (dfspec['SYSTEM NAME'].str.contains('\\(INTEL XEON'))]\n",
    "dfspecintel = dfspecintel[ (dfspecintel['SYSTEM NAME'].str.contains('GHZ'))]\n",
    "\n",
    "dfspecintel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating Technology Partner\n",
    "These are the top Technology Partner submissions in the SAPS Intel Xeon submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfintel.groupby(\"Technology Partner\")[\"Certification Number\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the top TEST SPONSOR submissions in SPEC. We have to \"fix\" these so that a join is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel.groupby(\"TEST SPONSOR\")[\"RESULTS BASE 2006\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel = dfspecintel.replace(to_replace='DELL INC.', value='DELL', regex=False)\n",
    "dfspecintel = dfspecintel.replace(to_replace='DELL INC', value='DELL', regex=False)\n",
    "dfspecintel = dfspecintel.replace(to_replace='BULL SAS', value='BULL', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel.groupby(\"TEST SPONSOR\")[\"RESULTS BASE 2006\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the \"Intel Xeon\" SAPS dataframe and filter the Intel SPEC dataframe by Technology Partner / TEST SPONSOR, Cores / PROCESSOR ENABLED CORES, Server Name / SYSTEM NAME (substring), CPU Speed / SYSTEM NAME (substring).\n",
    "\n",
    "When we only match the Xeon model number, core count, and clock speed, we get a good number of matches but there's a lot of duplication. We should only keep the unique entries from the SAPS dataframe (i.e. Certification Number).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "c = 0\n",
    "d = 0\n",
    "e = 0\n",
    "\n",
    "# 3 or more digits.. assume this is the Xeon model number\n",
    "r1 = re.compile('\\s+([a-zA-Z0-9_-]*\\d{3,})')\n",
    "\n",
    "# assume this is clock speed\n",
    "r2 = re.compile('(\\d+\\.\\d+)\\s?GHZ')\n",
    "\n",
    "newdf = pd.DataFrame()\n",
    "newdf2 = pd.DataFrame()\n",
    "\n",
    "while (c < len(dfintel.index)):\n",
    "    \n",
    "    row = dfintel.iloc[c]\n",
    "    tech_partner = row['Technology Partner']\n",
    "    server_name =  row['Server Name']\n",
    "    cpu_arch = row['CPU Architecture']\n",
    "    cpu_speed = row['CPU Speed']\n",
    "    cores = row['Cores']\n",
    "    certnum = row['Certification Number']\n",
    "    certdate = row['Certification Date']\n",
    "    saps = row['saps']\n",
    "\n",
    "\n",
    "    # for CPU architecture we just want to extract the 4-digit Xeon model number\n",
    "    m = r1.search( cpu_arch )\n",
    "    if m:\n",
    "        model = m.group(1)\n",
    "\n",
    "    # for CPU speed, we want to get rid of the GHZ bit\n",
    "    m = r2.match( cpu_speed )\n",
    "    if m:\n",
    "        clock_speed = m.group(1)\n",
    "\n",
    "    if ((len(model) > 0) & (len(clock_speed))) > 0:\n",
    "        # just match Xeon model number, cores, clock speed\n",
    "        res = dfspecintel[ (\n",
    "            (dfspecintel['PROCESSOR ENABLED CORES'] == cores) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(clock_speed)) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(model)) \n",
    "        )]\n",
    "        \n",
    "        if len(res.index) > 0:\n",
    "            res[\"Technology Partner\"] = tech_partner\n",
    "            res[\"Server Name\"] = server_name\n",
    "            res[\"CPU Architecture\"] = cpu_arch\n",
    "            res[\"CPU Speed\"] = cpu_speed\n",
    "            res[\"Cores\"] = cores\n",
    "            res['Certification Number'] = certnum\n",
    "            res['Certification Date'] = certdate\n",
    "            res['SAPS'] = saps\n",
    "            \n",
    "            newdf = newdf.append(res)\n",
    "            d = d + 1\n",
    "\n",
    "    c = c + 1\n",
    "\n",
    "print('%d out of %d matched' % (d, c))\n",
    "newdf = newdf.drop_duplicates(subset=['Certification Number'], keep='first')\n",
    "\n",
    "newdf.sort_values(['Certification Number'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the correlated values\n",
    "newdf.to_csv(\"correlated_base.csv\", index=False)\n",
    "\n",
    "# cleaned-up for manual sanity-checking\n",
    "newdf_clean = newdf.copy()\n",
    "newdf_clean = newdf_clean.drop(newdf_clean.columns[[0, 5, 6, 10, 11]], axis=1)\n",
    "\n",
    "newdf_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_clean['SAPS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_clean['RESULTS BASE 2006'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While correlation of SAPS and cint_rate_base2006 is very good, a linear fit won't be accurate for very small or very large machines; small machines have proportionately higher SAPS per cint_rate_base2006 (up to 140+) while large systems have proportionately lower SAPS per cint_rate_base2006 (around 50).\n",
    "\n",
    "Also, the lowest reported SAPS for the Intel Xeon machines is around 10000, but there are older/smaller systems that need to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_clean['SAPS'].corr(newdf['RESULTS BASE 2006'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Fitting\n",
    "We evaluate a polynomial fit for better predictive accuracy. The RISC-only manually labeled results are not very accurate by themselves, so we use the consolidated results. Let's first reshape the data into a useful format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the automatically-labeled Intel results\n",
    "d2 = newdf_clean[['RESULTS BASE 2006', 'SAPS' ]].copy()\n",
    "\n",
    "d2['RESULTS BASE 2006'] = pd.to_numeric(d2['RESULTS BASE 2006'], errors='coerce')\n",
    "d2['SAPS'] = pd.to_numeric(d2['SAPS'], errors='coerce')\n",
    "\n",
    "## FIXME: remove entries where the SPEC is > 10000\n",
    "d2 = d2[ (d2['RESULTS BASE 2006'] < 10000) ]\n",
    "\n",
    "d2.to_csv(\"saps_to_spec_correlated_vals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d2.iloc[:, 0].values.reshape(-1, 1)\n",
    "y = d2.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "X_seq = np.linspace(X.min(),X.max(),len(d2)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to find the polynomial degree which will result in the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))\n",
    "\n",
    "degree = np.arange(0, 7)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y,\n",
    "                                          'polynomialfeatures__degree', degree, cv=7)\n",
    "\n",
    "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like degree=1 gives the best fit, so a polynomial fit is not required at all, linear regression would do fine. However, to more accurately model the outliers, an increased degree may be desirable. We do note that when degree > 5 overfitting already occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=1\n",
    "\n",
    "polyreg=make_pipeline(PolynomialFeatures(degree),LinearRegression())\n",
    "polyreg.fit(X,y)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X_seq,polyreg.predict(X_seq),color=\"black\")\n",
    "plt.title(\"Polynomial regression with degree \"+str(degree))\n",
    "plt.show()\n",
    "\n",
    "c = np.polyfit(d2['RESULTS BASE 2006'], d2['SAPS'], degree)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Regressors\n",
    "A RandomForestRegressor results in better results than the GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn import ensemble, neural_network\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = d2.iloc[:, 0].values.reshape(-1, 1)\n",
    "y = d2.iloc[:, 1].values.reshape(-1, 1)\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_training_set, x_test_set, y_training_set, y_test_set = train_test_split(X,y,test_size=0.20, \n",
    "                                                                          random_state=42,\n",
    "                                                                          shuffle=True)\n",
    "# GradientBoostingRegressor\n",
    "#params = {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 2,\n",
    "#          'learning_rate': 0.01, 'loss': 'huber', 'validation_fraction': 0.2,\n",
    "#            'n_iter_no_change': 5, 'tol': 0.0001 }\n",
    "#model = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "# this doesn't converge\n",
    "#params = { 'learning_rate': 'adaptive' }\n",
    "#model = neural_network.MLPRegressor(**params)\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': None, 'min_samples_split': 2, 'criterion': 'mse' }\n",
    "model = ensemble.RandomForestRegressor(**params)\n",
    "\n",
    "model.fit(x_training_set, y_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.score(x_training_set,y_training_set)\n",
    "\n",
    "print('R2 sq: ', model_score)\n",
    "y_predicted = model.predict(x_test_set)\n",
    "\n",
    "print(\"Mean Squared Error: %.2f\"% mean_squared_error(y_test_set, y_predicted))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Test Variance Score: %.2f' % r2_score(y_test_set, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our model so that we don't need to go through the pain and suffering of re-training again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_filename = \"cint_rate_base2006_to_saps.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see in the graph below that this model has a huge error for a large valued data point (actual is 800K+ and predicted is less than 600K). This is a single data point (the Fujitsu M10-4S).  As new SAPS and SPEC ratings come up for newer and larger machines, this model will have to be re-trained\n",
    "\n",
    "The most conservative way to approach this problem is to simply reject any queries where the cint_rate_base2006 is more than 10000 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test_set, y_predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test_set.min(), y_test_set.max()], [y_test_set.min(), y_test_set.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title(\"Ground Truth vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula for SAPS from cint_rate_base2006\n",
    "def spec2saps(spec: float) -> float:\n",
    "    i = 0\n",
    "    saps = 0\n",
    "    while i < len(c):\n",
    "        p = (len(c) - 1) - i\n",
    "        saps = saps + c[i] * (spec**p)\n",
    "        i = i + 1\n",
    "   \n",
    "    return (round(saps,-1))\n",
    "\n",
    "def spec2saps2(spec: float) -> float:\n",
    "    a = np.array([spec])\n",
    "    a = np.expand_dims(a, 0)\n",
    "    saps = model.predict(a)[0]\n",
    "\n",
    "    return (round(saps,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's compare the polynomial fit with the ensemble model. Over the (small) manual validation set, the ensemble model provides qualitatively better results than the polynomial fit, except for the single very large sample (M10-4S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fujitsu M10-4S (836550 SAPS and 13625.00 cint_rate_base2006)\n",
    "print (spec2saps(13625))\n",
    "print (spec2saps2(13625))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUN FIRE V490 (ULTRASPARC IV, 6750 SAPS, 71.70 cint_rate_base2006)\n",
    "print (spec2saps(71.70))\n",
    "print (spec2saps2(71.70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intel Xeon 7140M (10380 SAPS, 76.9 cint_rate_base2006)\n",
    "print (spec2saps(76.9))\n",
    "print (spec2saps2(76.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sun M9000 (2.88GHz, 175600 SAPS and 2400 cint_rate_base2006)\n",
    "\n",
    "print (spec2saps(2400))\n",
    "print (spec2saps2(2400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sun M3000 (2.52GHz, 4130 SAPS and 25.7 cint_rate_base2006)\n",
    "print (spec2saps(25.7))\n",
    "print (spec2saps2(25.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM POWER 730, 47600 SAPS, 515 cint_rate_base2006, the error is large because the model is mostly influenced\n",
    "# by Intel Xeon data points\n",
    "print (spec2saps(515))\n",
    "print (spec2saps2(515))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an Intel Xeon data point.. good fit\n",
    "# CISCO UCS C260 M2 (INTEL XEON E7-2870, 2.40 GHZ)  36600 SAPS, 526 cint_rate_base2006\n",
    "print (spec2saps(526))\n",
    "print (spec2saps2(526))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another Intel Xeon data point (a rather large system)\n",
    "# CISCO UCS B200 M5 (INTEL XEON PLATINUM 8276, 2.20GHZ) 131170 SAPS, 2868.71 cint_rate_base2006\n",
    "print (spec2saps(2868.71))\n",
    "print (spec2saps2(2868.71))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
