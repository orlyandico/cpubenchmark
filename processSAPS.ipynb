{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the SAP Sales & Distribution Benchmark\n",
    "In this notebook, we attempt to correlate SPECintbase2006 with an arbitrary \"SAPS per Core\" that we obtain from the SAP Sales & Distribution 2-tier benchmark.\n",
    "\n",
    "This is because there is a much larger volume of SPECint2006 data, as compared to SAP SD2 data. If we accept the assumption that SAP SD2 is a reasonable approximation of an enterprise workload, and if we can find a good correlation between SPECint2006 and SAP SD2, then we can size enterprise workloads directly using SPECint2006 data, whch is quite abundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O export-sd.csv https://www.sap.com/dmc/exp/2018-benchmark-directory/assets/export-sd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsaps = pd.read_csv(\"export-sd.csv\", sep=\";\", error_bad_lines=False, header=0, encoding = \"ISO8859-1\")\n",
    "\n",
    "dfsaps['Server Name'] = dfsaps['Server Name'].str.upper() \n",
    "dfsaps['CPU Architecture'] = dfsaps['CPU Architecture'].str.upper() \n",
    "dfsaps['CPU Speed'] = dfsaps['CPU Speed'].str.upper() \n",
    "dfsaps['Technology Partner'] = dfsaps['Technology Partner'].str.upper() \n",
    "\n",
    "# we should only get 2-tier results\n",
    "dfsaps = dfsaps[ dfsaps['Configuration'] == '2-tier' ]\n",
    "\n",
    "dfsaps = dfsaps.drop(dfsaps.columns[[8, 12, 13, 14, 22, 24]], axis=1)\n",
    "\n",
    "# unfortunately some of the benchmarks have incorrect core counts\n",
    "# e.g. 2005021 has a null value for Cores in the CSV (but the long description shows 32 processors)\n",
    "# so we just drop any entries where Cores is not defined\n",
    "\n",
    "dfsaps.dropna(subset=['Cores'], inplace=True)\n",
    "\n",
    "\n",
    "# also, there are further errors in the CSV e.g. 2013010 reports 64 cores, but the details show 8 x \n",
    "# calculate a naive \"SAPS per Core\" value\n",
    "dfsaps['SAPS per Core'] = dfsaps['saps'] / dfsaps['Cores']\n",
    "\n",
    "dfsaps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsaps.to_csv(\"saps.csv\", index=False)\n",
    "dfsaps.sort_values(['SAPS per Core'], ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Derive Correlation Between SAPS and SPEC\n",
    "SAPS is a whole-system, complex benchmark, which is more relevant for enterprise workloads. However, the number of available SAPS benchmarks is low. If we can find a strong correlation between SAPS and SPEC, then we can use SPEC as a proxy for estimating performance of different processor architectures on SAPS-like, enterprise workloads.\n",
    "\n",
    "To get a good match between SAPS and SPEC, we will only use SAPS with \"INTEL XEON\" in the CPU Architecture description. This is 296 entries which is a little less than half of the total entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfintel = dfsaps[ (dfsaps['CPU Architecture'].str.contains(r'^INTEL XEON'))].sort_values(['SAPS per Core'], ascending=[False])\n",
    "\n",
    "dfintel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SPEC ratings, and extract only those for INTEL XEON where a clock speed is specified in SYSTEM NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspec = pd.read_csv(\"spec.csv\")\n",
    "\n",
    "# only get the SPEC results for INTEL XEON which have a clock speed (so we can match it to the SAPS dataframe)\n",
    "dfspecintel = dfspec[ (dfspec['SYSTEM NAME'].str.contains('\\(INTEL XEON'))]\n",
    "dfspecintel = dfspecintel[ (dfspecintel['SYSTEM NAME'].str.contains('GHZ'))]\n",
    "\n",
    "dfspecintel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating Technology Partner\n",
    "These are the top Technology Partner submissions in the SAPS Intel Xeon submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfintel.groupby(\"Technology Partner\")[\"Certification Number\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the top TEST SPONSOR submissions in SPEC. We have to \"fix\" these so that a join is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel.groupby(\"TEST SPONSOR\")[\"RESULTS BASE 2006\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel = dfspecintel.replace(to_replace='DELL INC.', value='DELL', regex=False)\n",
    "dfspecintel = dfspecintel.replace(to_replace='DELL INC', value='DELL', regex=False)\n",
    "dfspecintel = dfspecintel.replace(to_replace='BULL SAS', value='BULL', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspecintel.groupby(\"TEST SPONSOR\")[\"RESULTS BASE 2006\"].count().head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the \"Intel Xeon\" SAPS dataframe and filter the Intel SPEC dataframe by Technology Partner / TEST SPONSOR, Cores / PROCESSOR ENABLED CORES, Server Name / SYSTEM NAME (substring), CPU Speed / SYSTEM NAME (substring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "c = 0\n",
    "d = 0\n",
    "e = 0\n",
    "\n",
    "# 3 or more digits.. assume this is the Xeon model number\n",
    "r1 = re.compile('\\s+([a-zA-Z0-9_-]*\\d{3,})')\n",
    "\n",
    "# assume this is clock speed\n",
    "r2 = re.compile('(\\d+\\.\\d+)\\s?GHZ')\n",
    "\n",
    "newdf = pd.DataFrame()\n",
    "newdf2 = pd.DataFrame()\n",
    "\n",
    "while (c < len(dfintel.index)):\n",
    "    \n",
    "    row = dfintel.iloc[c]\n",
    "    tech_partner = row['Technology Partner']\n",
    "    server_name =  row['Server Name']\n",
    "    cpu_arch = row['CPU Architecture']\n",
    "    cpu_speed = row['CPU Speed']\n",
    "    cores = row['Cores']\n",
    "    certnum = row['Certification Number']\n",
    "    certdate = row['Certification Date']\n",
    "    saps = row['saps']\n",
    "    saps_per_core = row['SAPS per Core']\n",
    "\n",
    "\n",
    "    # for CPU architecture we just want to extract the 4-digit Xeon model number\n",
    "    m = r1.search( cpu_arch )\n",
    "    if m:\n",
    "        model = m.group(1)\n",
    "\n",
    "    # for CPU speed, we want to get rid of the GHZ bit\n",
    "    m = r2.match( cpu_speed )\n",
    "    if m:\n",
    "        clock_speed = m.group(1)\n",
    "\n",
    "    if ((len(model) > 0) & (len(clock_speed))) > 0:\n",
    "        # just match Xeon model number, cores, clock speed\n",
    "        res = dfspecintel[ (\n",
    "#            (dfspecintel['TEST SPONSOR'] == tech_partner) &\n",
    "            (dfspecintel['PROCESSOR ENABLED CORES'] == cores) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(clock_speed)) &\n",
    "#            (dfspecintel[\"SYSTEM NAME\"].str.contains(server_name)) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(model)) \n",
    "        )]\n",
    "        \n",
    "        # stricter match including manufacturer and server name\n",
    "        res2 =  dfspecintel[ (\n",
    "            (dfspecintel['TEST SPONSOR'] == tech_partner) &\n",
    "            (dfspecintel['PROCESSOR ENABLED CORES'] == cores) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(clock_speed)) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(server_name)) &\n",
    "            (dfspecintel[\"SYSTEM NAME\"].str.contains(model)) \n",
    "        )]\n",
    "\n",
    "        if len(res.index) > 0:\n",
    "            res[\"Technology Partner\"] = tech_partner\n",
    "            res[\"Server Name\"] = server_name\n",
    "            res[\"CPU Architecture\"] = cpu_arch\n",
    "            res[\"CPU Speed\"] = cpu_speed\n",
    "            res[\"Cores\"] = cores\n",
    "            res['Certification Number'] = certnum\n",
    "            res['Certification Date'] = certdate\n",
    "            res['SAPS'] = saps\n",
    "            res['SAPS per Core'] = saps_per_core\n",
    "            \n",
    "            newdf = newdf.append(res)\n",
    "            d = d + 1\n",
    "\n",
    "        if len(res2.index) > 0:\n",
    "            res2[\"Technology Partner\"] = tech_partner\n",
    "            res2[\"Server Name\"] = server_name\n",
    "            res2[\"CPU Architecture\"] = cpu_arch\n",
    "            res2[\"CPU Speed\"] = cpu_speed\n",
    "            res2[\"Cores\"] = cores\n",
    "            res2['Certification Number'] = certnum\n",
    "            res2['Certification Date'] = certdate\n",
    "            res2['SAPS'] = saps\n",
    "            res2['SAPS per Core'] = saps_per_core\n",
    "            \n",
    "            newdf2 = newdf2.append(res2)\n",
    "            e = e + 1\n",
    "\n",
    "    c = c + 1\n",
    "\n",
    "print('%d, %d of %d matched' % (d, e, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we only match the Xeon model number, core count, and clock speed, we get a good number of matches. This allows for a larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.sort_values(['Certification Number'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv(\"correlated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that the entries with matching/correlated data have a minimum SAPS per core of 924, which is not a very old machine. Each submission in the SAPS benchmark results in multiple matches in the SPECintbase2006 benchmark. \n",
    "\n",
    "Correlation of SAPS per core and SPECintbase2006 is not very strong. However, we are able to obtain a reasonable best-fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['SAPS per Core'].corr(newdf['RESULTS BASE 2006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d2 = newdf[['RESULTS BASE 2006', 'SAPS per Core', ]].copy()\n",
    "\n",
    "X = d2.iloc[:, 0].values.reshape(-1, 1)\n",
    "Y = d2.iloc[:, 1].values.reshape(-1, 1)\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X, Y)\n",
    "Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(X, Y_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "print('Coefficient/Intercept: %f %f\\n' % ( linear_regressor.coef_, linear_regressor.intercept_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with the much smaller exact data set. Notice that the correlation is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2['SAPS per Core'].corr(newdf2['RESULTS BASE 2006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = newdf2[['RESULTS BASE 2006', 'SAPS per Core', ]].copy()\n",
    "\n",
    "X = d2.iloc[:, 0].values.reshape(-1, 1)\n",
    "Y = d2.iloc[:, 1].values.reshape(-1, 1)\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X, Y)\n",
    "Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(X, Y_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "print('Coefficient/Intercept: %f %f\\n' % ( linear_regressor.coef_, linear_regressor.intercept_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial fitting for potentially better correlation\n",
    "\n",
    "We can try different degrees to find a better fit; too high a degree will result in overfitting. A degree of 3 looks empirically sufficient to model the old/slow machines properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = newdf[['RESULTS BASE 2006', 'SAPS per Core', ]].copy()\n",
    "\n",
    "X = d2.iloc[:, 0].values.reshape(-1, 1)\n",
    "Y = d2.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "X_seq = np.linspace(X.min(),X.max(),300).reshape(-1,1)\n",
    "\n",
    "# change this as an experiment\n",
    "degree=3\n",
    "\n",
    "polyreg=make_pipeline(PolynomialFeatures(degree),LinearRegression())\n",
    "polyreg.fit(X,Y)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(X_seq,polyreg.predict(X_seq),color=\"black\")\n",
    "plt.title(\"Polynomial regression with degree \"+str(degree))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above polynomial fit that SAPS will be generally over-estimated at the low end (where SPECintbase2006 is 20 or less). This will have the tendency of inflating the SAPS rating of old/slow boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = ax^3 + bx^2 + cx + d\n",
    "c = np.polyfit(d2['RESULTS BASE 2006'],d2['SAPS per Core'], degree)\n",
    "print(c)\n",
    "\n",
    "# formula for SAPS from SPECintbase2006\n",
    "def spec2saps(spec: float) -> float:\n",
    "    saps = c[0]*spec**3 + c[1]*spec**2 + c[2]*spec + c[3]\n",
    "\n",
    "    # the lowest possible SAPS per core on the official benchmark is 145 (Sun T2000)\n",
    "    if (saps < 145):\n",
    "        saps = 145\n",
    "    return (saps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sun M3000 (actual SAPS/core = 1032)\n",
    "print (spec2saps(13.58))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There is a strong correlation between SAPS (per core) and SPECintbase2006, even when only doing a simple linear regression. With the larger data set, the best-fit line is defined approximately by:\n",
    "\n",
    "**SAPS per Core = (20.57 * SPECintbase2006) + 1061**\n",
    "\n",
    "The above formula **will not work** for really old systems with very low SPECintbase2006. If we posit a pathological system with **ZERO** SPECintbase2006, the formula would still predict a SAPS per core of 1061.\n",
    "\n",
    "Example: Sun M3000 with 4 cores reports 4130 SAPS and 1032 SAPS/core. Average SPECintbase2006 for this system is 13.58. The above formula predicts a SAPS per core (based on SPECintbase2006) of 1340 using the linear regression. This is much higher than the actual SAPS per core of 1032. Meanwhile, if we use a polynomial fit with degree 3, the predicted SAPS is 890 which is less than actual.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
